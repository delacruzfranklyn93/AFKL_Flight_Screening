{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "floral-bidder",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pymongo\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from splinter import Browser\n",
    "import pandas as pd\n",
    "import json\n",
    "import html5lib\n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "physical-vessel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 91.0.4472\n",
      "[WDM] - Get LATEST driver version for 91.0.4472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver [C:\\Users\\delac\\.wdm\\drivers\\chromedriver\\win32\\91.0.4472.101\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "#setup splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1577b902",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14689e90",
   "metadata": {},
   "source": [
    "# Retrieve the CSV's and Convert to DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "multiple-tunisia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the URL to visit\n",
    "url = 'https://aflsbkg.airfrance.fr/'\n",
    "\n",
    "# Visit the URL\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f57f1460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What day(s) do you wish to screen21\n",
      "Input the month in 3 word format (Ex = Apr)Jun\n"
     ]
    }
   ],
   "source": [
    "# Store origin and Destination for Airfrance and KLM\n",
    "AF_flight = [\"ORD\", \"CDG\"]\n",
    "KL_flight =  [\"ORD\", \"AMS\"]\n",
    "\n",
    "# Store the date Variable (day, month, year)\n",
    "day = list(map(int, input(\"What day(s) do you wish to screen\").split(\",\")))\n",
    "month = input(\"Input the month in 3 word format (Ex = Apr)\").title()\n",
    "year = \"2021\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-startup",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\delac\\anaconda3\\envs\\PythonData\\lib\\site-packages\\splinter\\driver\\webdriver\\__init__.py:485: FutureWarning: browser.find_link_by_partial_href is deprecated. Use browser.links.find_by_partial_href instead.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# navigate to the correct webpage for CSV download\n",
    "browser.links.find_by_partial_text('Booking').click()\n",
    "browser.links.find_by_partial_text('Search').click()\n",
    "\n",
    "time.sleep(2.00)\n",
    "\n",
    "# fill the flight number and date input field\n",
    "browser.fill(\"segment.segOrigin\", f\"{AF_flight[0]}\")\n",
    "browser.fill(\"segment.segDestination\", f\"{AF_flight[1]}\")\n",
    "browser.fill(\"bookingSearch.legDepartureDate\", f\"{day[0]}/{month}/{year}\")\n",
    "\n",
    "# filter the search for the flight needed\n",
    "browser.links.find_by_partial_text('Filter').click()\n",
    "\n",
    "time.sleep(3.00)\n",
    "\n",
    "# browser.click_link_by_id('FILTER_EXPAND_COLLAPSE')\n",
    "#Visit inital page and scrape the first page data\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "table = soup.find_all('table', class_= 'listTable')\n",
    "df = pd.read_html(str(table))[0]\n",
    "\n",
    "# Create a for loop to visit the other pages of data and concat with original df\n",
    "num = 2\n",
    "for y in range(10):\n",
    "    try:\n",
    "        browser.click_link_by_partial_href(f'newbookListPagingProcess.do?page={num}')\n",
    "        html1 = browser.html\n",
    "        soup1 = bs(html1, 'html.parser')\n",
    "        table1 = soup1.find_all('table', class_= 'listTable')\n",
    "        df2 = pd.read_html(str(table1))[0]\n",
    "        df = pd.concat([df, df2], ignore_index=True)\n",
    "        num += 1\n",
    "    except:\n",
    "        break\n",
    "AF = df[(df.Prefix == '006') | (df.Prefix == '057')].drop(['Unnamed: 0'], axis = 1)\n",
    "\n",
    "browser.links.find_by_partial_text('Booking').click()\n",
    "browser.links.find_by_partial_text('Search').click()\n",
    "\n",
    "time.sleep(3.00)\n",
    "\n",
    "browser.fill(\"segment.segOrigin\", f\"{KL_flight[0]}\")\n",
    "browser.fill(\"segment.segDestination\", f\"{KL_flight[1]}\")\n",
    "browser.fill(\"bookingSearch.legDepartureDate\", f\"{day[0]}/{month}/{year}\")\n",
    "\n",
    "\n",
    "# filter the search for the flight needed\n",
    "browser.links.find_by_partial_text('Filter').click()\n",
    "\n",
    "time.sleep(3.00)\n",
    "\n",
    "# browser.click_link_by_id('FILTER_EXPAND_COLLAPSE')\n",
    "#Visit inital page and scrape the first page data\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "table = soup.find_all('table', class_= 'listTable')\n",
    "df = pd.read_html(str(table))[0]\n",
    "\n",
    "# Create a for loop to visit the other pages of data and concat with original df\n",
    "num = 2\n",
    "for y in range(10):\n",
    "    try:\n",
    "        browser.click_link_by_partial_href(f'newbookListPagingProcess.do?page={num}')\n",
    "        html1 = browser.html\n",
    "        soup1 = bs(html1, 'html.parser')\n",
    "        table1 = soup1.find_all('table', class_= 'listTable')\n",
    "        df2 = pd.read_html(str(table1))[0]\n",
    "        df = pd.concat([df, df2], ignore_index=True)\n",
    "        num += 1\n",
    "    except:\n",
    "        break\n",
    "KL = df[(df.Prefix == '057') |(df.Prefix == '074') ].drop(['Unnamed: 0'], axis = 1)\n",
    "\n",
    "df_final = pd.concat([AF, KL], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20612c04",
   "metadata": {},
   "source": [
    "# Filter the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac8e7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns you want to display and store in a list\n",
    "\n",
    "columns = [\"Prefix\", \"AWB Number\", \"Origin\",\"Destination\",\"Commodity\", \\\n",
    "           \"Product\",\"Pieces\", \"Weight\",\"Volume\",\"Issuer\",\"Flight Info\"]\n",
    "\n",
    "# Filter the AWB's by  weight and volume \n",
    "df_final = df_final[(df_final.Weight.astype('float') > 1000) & (df_final.Volume.astype(\"float\") > 10.00)][columns]\n",
    "\n",
    "# Filter the AWB's by product\n",
    "df_final = df_final[~df_final.Product.str.contains(\"S50|S51|S52|S53\")].sort_values('Flight Info').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17c5007",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(columns = columns)\n",
    "# append an empty row for csv formating. \n",
    "df_test = df_test.append(pd.Series(name= \" \")).fillna(\"\")\n",
    "\n",
    "# append the first flight that it shows \n",
    "df_test = df_test.append(pd.Series(name= df_final[\"Flight Info\"][0])).fillna(\"\")\n",
    "past_flight = df_final[\"Flight Info\"][0]\n",
    "\n",
    "for index, row in df_final.iterrows():\n",
    "    if past_flight != row[\"Flight Info\"]:\n",
    "        df_test = df_test.append(pd.Series(name= \" \")).fillna(\"\")\n",
    "        df_test = df_test.append(pd.Series(name= row[\"Flight Info\"])).fillna(\"\")\n",
    "        df_test = df_test.append(row)\n",
    "    else:\n",
    "        df_test = df_test.append(row)\n",
    "    past_flight = row[\"Flight Info\"]\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7e7ea5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test.to_csv(\"test.csv\")\n",
    "len(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee4f271",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcbfc75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
